{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMA8/XXXBp6m9+0pyT03WGi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JUD210/AIFFEL_quest_cr/blob/main/Python/DA01/da_with_py_6_2_wine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln7igTfZeCnI",
        "outputId": "94952d3c-3658-4cdf-bda7-e62e7cd61ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn version: 1.3.2\n"
          ]
        }
      ],
      "source": [
        "# 6-2. 프로젝트 (2) load_wine : 와인을 분류해 봅시다\n",
        "\n",
        "# 라이브러리 버전 확인\n",
        "import sklearn\n",
        "print(f\"sklearn version: {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) 필요한 모듈 import하기\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "EjG5AA_VelQq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) 데이터 준비\n",
        "wine = load_wine()\n",
        "print(type(wine))\n",
        "print(wine.keys())"
      ],
      "metadata": {
        "id": "mKnVajK0evxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0d912f-c21d-4326-cad1-725548a54200"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils._bunch.Bunch'>\n",
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) 데이터 이해하기\n",
        "# Feature Data 지정하기\n",
        "X = wine.data\n",
        "print(\"\\nX: \", X)\n",
        "print(\"\\nData Shape:\", X.shape)\n",
        "print(\"\\nFeature Data Sample: \", X[0])\n",
        "print(\"\\nFeature Names:\", wine.feature_names)\n",
        "print(\"len(wine.feature_names): \", len(wine.feature_names))\n",
        "\n",
        "# Label Data 지정하기\n",
        "y = wine.target\n",
        "print(\"Label Shape:\", y.shape)\n",
        "print(\"\\nLabel Data Sample: \", y[0])\n",
        "\n",
        "# Target Names 출력해 보기\n",
        "print(\"Target Names:\", wine.target_names)\n",
        "print(\"len(wine.target_names): \", len(wine.target_names))\n",
        "\n",
        "# 데이터 Describe 해 보기\n",
        "\n",
        "print(\"\\nDescription:\")\n",
        "print(wine.DESCR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG16Gbqze0Hc",
        "outputId": "5753bdfb-9e06-4aef-b8f6-c726e1bee262"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "X:  [[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
            " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
            " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
            " ...\n",
            " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
            " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
            " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
            "\n",
            "Data Shape: (178, 13)\n",
            "\n",
            "Feature Data Sample:  [1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
            "\n",
            "Feature Names: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wine', 'proline']\n",
            "len(wine.feature_names):  13\n",
            "Label Shape: (178,)\n",
            "\n",
            "Label Data Sample:  0\n",
            "Target Names: ['class_0' 'class_1' 'class_2']\n",
            "len(wine.target_names):  3\n",
            "\n",
            "Description:\n",
            ".. _wine_dataset:\n",
            "\n",
            "Wine recognition dataset\n",
            "------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 178\n",
            "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            " \t\t- Alcohol\n",
            " \t\t- Malic acid\n",
            " \t\t- Ash\n",
            "\t\t- Alcalinity of ash  \n",
            " \t\t- Magnesium\n",
            "\t\t- Total phenols\n",
            " \t\t- Flavanoids\n",
            " \t\t- Nonflavanoid phenols\n",
            " \t\t- Proanthocyanins\n",
            "\t\t- Color intensity\n",
            " \t\t- Hue\n",
            " \t\t- OD280/OD315 of diluted wine\n",
            " \t\t- Proline\n",
            "\n",
            "    - class:\n",
            "            - class_0\n",
            "            - class_1\n",
            "            - class_2\n",
            "\t\t\n",
            "    :Summary Statistics:\n",
            "    \n",
            "    ============================= ==== ===== ======= =====\n",
            "                                   Min   Max   Mean     SD\n",
            "    ============================= ==== ===== ======= =====\n",
            "    Alcohol:                      11.0  14.8    13.0   0.8\n",
            "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
            "    Ash:                          1.36  3.23    2.36  0.27\n",
            "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
            "    Magnesium:                    70.0 162.0    99.7  14.3\n",
            "    Total Phenols:                0.98  3.88    2.29  0.63\n",
            "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
            "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
            "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
            "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
            "    Hue:                          0.48  1.71    0.96  0.23\n",
            "    OD280/OD315 of diluted wine: 1.27  4.00    2.61  0.71\n",
            "    Proline:                       278  1680     746   315\n",
            "    ============================= ==== ===== ======= =====\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "This is a copy of UCI ML Wine recognition datasets.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
            "\n",
            "The data is the results of a chemical analysis of wine grown in the same\n",
            "region in Italy by three different cultivators. There are thirteen different\n",
            "measurements taken for different constituents found in the three types of\n",
            "wine.\n",
            "\n",
            "Original Owners: \n",
            "\n",
            "Forina, M. et al, PARVUS - \n",
            "An Extendible Package for Data Exploration, Classification and Correlation. \n",
            "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
            "Via Brigata Salerno, 16147 Genoa, Italy.\n",
            "\n",
            "Citation:\n",
            "\n",
            "Lichman, M. (2013). UCI Machine Learning Repository\n",
            "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
            "School of Information and Computer Science. \n",
            "\n",
            "|details-start|\n",
            "**References**\n",
            "|details-split|\n",
            "\n",
            "(1) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "Comparison of Classifiers in High Dimensional Settings, \n",
            "Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
            "Mathematics and Statistics, James Cook University of North Queensland. \n",
            "(Also submitted to Technometrics). \n",
            "\n",
            "The data was used with many others for comparing various \n",
            "classifiers. The classes are separable, though only RDA \n",
            "has achieved 100% correct classification. \n",
            "(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
            "(All results using the leave-one-out technique) \n",
            "\n",
            "(2) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "\"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
            "Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
            "Mathematics and Statistics, James Cook University of North Queensland. \n",
            "(Also submitted to Journal of Chemometrics).\n",
            "\n",
            "|details-end|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) train, test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"X_train shape:\", X_train.shape, X_train[0])\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape, y_train[0])\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "uebi9c0We1ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca52e49a-7c19-47c2-ed12-87ea84aff522"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (142, 13) [1.434e+01 1.680e+00 2.700e+00 2.500e+01 9.800e+01 2.800e+00 1.310e+00\n",
            " 5.300e-01 2.700e+00 1.300e+01 5.700e-01 1.960e+00 6.600e+02]\n",
            "X_test shape: (36, 13)\n",
            "y_train shape: (142,) 2\n",
            "y_test shape: (36,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (5) 다양한 모델로 학습시켜보기\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM\": SVC(random_state=42),\n",
        "    \"SGD Classifier\": SGDClassifier(random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=4000)\n",
        "    # \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=3000, solver=\"saga\")\n",
        "    # \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000, solver='lbfgs')\n",
        "    # 오류\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"\\n{name} trained.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Lsg_I6e2XK",
        "outputId": "3de7945f-8949-4428-94e4-79f60c083457"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree trained.\n",
            "\n",
            "Random Forest trained.\n",
            "\n",
            "SVM trained.\n",
            "\n",
            "SGD Classifier trained.\n",
            "\n",
            "Logistic Regression trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해 보기\n",
        "\n",
        "# for name, model in models.items():\n",
        "#     y_pred = model.predict(X_test)\n",
        "\n",
        "#     print(f\"\\n{name} 평가 결과:\")\n",
        "\n",
        "\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    return {\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred, average='weighted', zero_division=1),\n",
        "        'Recall': recall_score(y_true, y_pred, average='weighted'),\n",
        "        'F1 Score': f1_score(y_true, y_pred, average='weighted', zero_division=1)\n",
        "    }\n",
        "\n",
        "# 모델들의 평가 결과를 저장할 리스트 초기화\n",
        "model_results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 각 모델별 평가 결과 출력\n",
        "    print(f\"\\n{name} 평가 결과:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=wine.target_names.astype(str), zero_division=1))\n",
        "\n",
        "    # 결과 저장\n",
        "    results = evaluate_model(y_test, y_pred)\n",
        "    results['Model'] = name\n",
        "    model_results.append(results)\n",
        "\n",
        "# 결과를 DataFrame으로 변환\n",
        "df_results = pd.DataFrame(model_results).set_index('Model')\n",
        "\n",
        "# 결과 출력\n",
        "print(\"\\n모델별 성능 비교 결과:\")\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iqgLZz3e3Gy",
        "outputId": "4f0fc79b-926e-45dc-8800-39e84810a0f0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree 평가 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class_0       0.93      0.93      0.93        14\n",
            "     class_1       0.93      1.00      0.97        14\n",
            "     class_2       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.95      0.93      0.94        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n",
            "\n",
            "Random Forest 평가 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      1.00      1.00        14\n",
            "     class_1       1.00      1.00      1.00        14\n",
            "     class_2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "\n",
            "SVM 평가 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      1.00      1.00        14\n",
            "     class_1       0.73      0.79      0.76        14\n",
            "     class_2       0.57      0.50      0.53         8\n",
            "\n",
            "    accuracy                           0.81        36\n",
            "   macro avg       0.77      0.76      0.76        36\n",
            "weighted avg       0.80      0.81      0.80        36\n",
            "\n",
            "\n",
            "SGD Classifier 평가 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class_0       0.81      0.93      0.87        14\n",
            "     class_1       0.65      0.93      0.76        14\n",
            "     class_2       1.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.72        36\n",
            "   macro avg       0.82      0.62      0.54        36\n",
            "weighted avg       0.79      0.72      0.63        36\n",
            "\n",
            "\n",
            "Logistic Regression 평가 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      1.00      1.00        14\n",
            "     class_1       1.00      1.00      1.00        14\n",
            "     class_2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "\n",
            "모델별 성능 비교 결과:\n",
            "                     Accuracy  Precision    Recall  F1 Score\n",
            "Model                                                       \n",
            "Decision Tree        0.944444   0.946296  0.944444  0.943997\n",
            "Random Forest        1.000000   1.000000  1.000000  1.000000\n",
            "SVM                  0.805556   0.801058  0.805556  0.802427\n",
            "SGD Classifier       0.722222   0.790972  0.722222  0.634423\n",
            "Logistic Regression  1.000000   1.000000  1.000000  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋의 특성에 따라 적절한 성능 평가 지표가 달라진다.\n",
        "- 클래스가 균등하게 분포된 데이터셋에서는 Accuracy가 적합.\n",
        "- 클래스 불균형이 심한 경우에는 Precision, Recall, 또는 F1-Score가 더 적합.\n",
        "\n",
        "평가지표는 `Accuracy`를 선택\n",
        "- wine 데이터셋의 경우, 모든 클래스가 비슷한 비율(14/14/8)로 존재하므로 모델이 얼마나 많은 샘플을 정확하게 분류했는지를 보는 것이 중요하기 때문.\n",
        "- 모든 지표가 비슷하다는 것은, 모델이 특정 클래스에만 성능이 치우치지 않고, Precision과 Recall에서의 균형이 잘 잡혀 있다는 의미하기 때문."
      ],
      "metadata": {
        "id": "Zb1gaQhSbLrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "# 6-2. 프로젝트 (2) load_wine : 와인을 분류해 봅시다\n",
        "\n",
        "이번에는 와인 데이터입니다. 와인의 어떤 특징으로 와인의 종류를 분류해 볼 수 있을까요?\n",
        "\n",
        "데이터에 어떤 정보가 담겨있는지, feature는 무엇이고 label은 무엇인지 확인해 보면서 진행하는 점, 잊지마세요!\n",
        "\n",
        "(1) 필요한 모듈 import하기\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "```\n",
        "\n",
        "(2) 데이터 준비\n",
        "load_wine 메서드를 사용합니다.\n",
        "\n",
        "(3) 데이터 이해하기\n",
        "지피지기면 백전불태! 다루어야 할 데이터를 자세히 살펴봅시다.\n",
        "\n",
        "- Feature Data 지정하기\n",
        "- Label Data 지정하기\n",
        "- Target Names 출력해 보기\n",
        "- 데이터 Describe 해 보기\n",
        "\n",
        "(4) train, test 데이터 분리\n",
        "모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.\n",
        "- X_train, X_test, y_train, y_test를 생성하는 방법을 참고해 보세요.\n",
        "\n",
        "(5) 다양한 모델로 학습시켜보기\n",
        "학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 봅시다. 어떤 모델이 가장 좋은 성능을 보일까요?\n",
        "\n",
        "- Decision Tree 사용해 보기\n",
        "- Random Forest 사용해 보기\n",
        "- SVM 사용해 보기\n",
        "- SGD Classifier 사용해 보기\n",
        "- Logistic Regression 사용해 보기\n",
        "\n",
        "(6) 모델을 평가해 보기\n",
        "학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요? sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요."
      ],
      "metadata": {
        "id": "2bldBuSteMTh"
      }
    }
  ]
}